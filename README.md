# DataShare
In this work, we describe a safe and secure architecture and semantic approach for data sharing that is based on blockchain, local differential privacy, and federated learning. The proposed framework generates an atmosphere devoid of trust in which data owners are no longer required to have trust in the controllers. The federated learning models enable the whole network to decentralize its data-driven learning. InterPlanetary File System (IPFS) is used to provide data security in a distributed environment because each file in IPFS has a digital fingerprint that is computed using a cryptographic hash function on the file’s whole contents. Due to the rigorous privacy guarantee, data owners no longer need to be worried about the security of their data. The proposed model’s assessment parameters include latency, throughput, privacy, and accuracy. The data privacy of the proposed model is protected via local differential privacy and federated learning, and its latency and throughput communication transactions on permissioned blockchain are calculated and compared to those of the benchmark model. The findings indicate that the proposed model delivers 85 percent more accurate privacy than the benchmark model.

The task is divided into two parts: registration and offers. A bid for a dataset is registered using the register function, and a bid is responded to with an offer using the offer function. In the federated learning process, we experimented with several arbitrary data owners. We went through twenty rounds of interaction, each comprising registration and complete trading processes (bidding, offers, and finalizing), as well as federated learning rounds. The accuracy of the federated learning process and transaction latency and throughput were all tested in our experiment. 
